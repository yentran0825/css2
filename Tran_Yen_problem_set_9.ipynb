{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tran_Yen_problem_set_9.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ-eUTIhFW8b"
      },
      "source": [
        "###Block 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5WlfknOCWJ7"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "data = sns.load_dataset('geyser')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xlFKctUFRYD"
      },
      "source": [
        "###Block 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHY28Av0Fa3K"
      },
      "source": [
        "def k_fold_function(X,y,folds):\n",
        "  training_score = []\n",
        "  testing_score = []\n",
        "\n",
        "  len_fold = (data.shape[0])//folds \n",
        "\n",
        "  #splitting data into train and test sets\n",
        "  Xtrain = []\n",
        "  Xtest = []\n",
        "\n",
        "  ytrain = []\n",
        "  ytest = []\n",
        "\n",
        "  for i in range(folds):\n",
        "    #length for the last fold as the dataset is uneven\n",
        "    if i == (folds - 1):\n",
        "      Xtrain = (X[:i*len_fold])\n",
        "      Xtest = (X[i*len_fold:])\n",
        "      ytrain = (y[:i*len_fold])\n",
        "      ytest = (y[i*len_fold:])\n",
        "    #length for the rest of the folds\n",
        "    else:\n",
        "      Xtrain = np.append(X[:i*len_fold], X[((i+1)*len_fold):])\n",
        "      Xtest = (X[i*len_fold:len_fold*(i+1)])\n",
        "      ytrain = np.append(y[:i*len_fold], y[((i+1)*len_fold):])\n",
        "      ytest = (y[i*len_fold:len_fold*(i+1)])\n",
        "\n",
        "    #print(Xtrain.shape) \n",
        "    #print(ytrain.shape) \n",
        "    Xtrain = Xtrain.reshape(Xtrain.shape[0],1)\n",
        "    Xtest = Xtest.reshape(Xtest.shape[0],1)\n",
        "\n",
        "    model = LinearRegression()\n",
        "    model.fit(Xtrain,ytrain)\n",
        "    training_score.append(model.score(Xtest, ytest))\n",
        "    testing_score.append(model.score(Xtrain, ytrain))\n",
        "\n",
        "  return training_score,testing_score"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOp5Zpy9FOvL"
      },
      "source": [
        "###Block 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdFLLrF831eS",
        "outputId": "0ea80c78-9aa1-460a-9492-f7797f48c4ea"
      },
      "source": [
        "X = np.array(data['duration'])\n",
        "y = np.array(data['waiting'])\n",
        "training_score, testing_score = k_fold_function(X,y,3)\n",
        "print(\"k fold = 3\")\n",
        "print(\"Average training score \" + str(np.mean(training_score)))\n",
        "print(\"Average testing score \" + str(np.mean(testing_score)))\n",
        "print(\"Std training score \" + str(np.std(training_score)))\n",
        "print(\"Std testing score : \" + str(np.std(testing_score)))\n",
        "\n",
        "\n",
        "training_score, testing_score = k_fold_function(X,y,5)\n",
        "print(\"k fold = 5\")\n",
        "print(\"Average training score: \" + str(np.mean(training_score)))\n",
        "print(\"Average testing score: \" + str(np.mean(testing_score)))\n",
        "print(\"Std training score: \" + str(np.std(training_score)))\n",
        "print(\"Std testing score: \" + str(np.std(testing_score)))\n",
        "\n",
        "training_score, testing_score = k_fold_function(X,y,10)\n",
        "print(\"k fold = 10\")\n",
        "print(\"Average training score: \" + str(np.mean(training_score)))\n",
        "print(\"Average testing score: \" + str(np.mean(testing_score)))\n",
        "print(\"Std training score: \" + str(np.std(training_score)))\n",
        "print(\"Std testing score: \" + str(np.std(testing_score)))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "k fold = 3\n",
            "Average training score 0.8004576648847967\n",
            "Average testing score 0.8121771711262316\n",
            "Std training score 0.029830869135937025\n",
            "Std testing score : 0.011968043511039845\n",
            "k fold = 5\n",
            "Average training score: 0.8056715142563547\n",
            "Average testing score: 0.8116959665550336\n",
            "Std training score: 0.020871940815441792\n",
            "Std testing score: 0.004389581073677524\n",
            "k fold = 10\n",
            "Average training score: 0.7972280065767442\n",
            "Average testing score: 0.8115509101080287\n",
            "Std training score: 0.06683036198666513\n",
            "Std testing score: 0.00522525331079697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgDKgrxFdQv"
      },
      "source": [
        "###Block 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdEZ_UMLEkwa"
      },
      "source": [
        "Because the folds split evenly and the data are not shuffled, the training and testing R^2 values are fairly constant throughout the folds. The average testing score throughout different folds is around 0.80, with an average testing score of 0.81. Both the training and testing scores have a small difference, suggesting that the model chosen is a good model!"
      ]
    }
  ]
}